# -*- coding: utf-8 -*-
"""resnet50_test.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16XhOsNYcLfaS1ubAbD11R288eQhTaW-C
"""

from google.colab import drive
drive.mount('/gdrive', force_remount=True)

from IPython.display import Image as ImageView
# ImageView('/gdrive/My Drive/datasets_12types/hyundai avante 2021/hyundai avante 2021_1.jpg')

import tensorflow as tf 
from tensorflow import keras 
from sklearn.model_selection import train_test_split
import numpy as np
from glob import glob
from PIL import Image
import matplotlib.pyplot as plt
import os

print(tf.__version__)
print(keras.__version__)

folder = glob('/gdrive/My Drive/datasets/*')
class_name = []
dic={}

for folderName in folder : 
  class_name.append(folderName.split('/')[4])

dicIdx = 0
for v in class_name :
  dic[v] = dicIdx
  dicIdx+=1

print(class_name)
print(dic)

# class_name = ['chevrolet spark 2020',
#               'chevrolet spark 2022',
#               'chevrolet trailblazer 2020',
#               'chevrolet trailblazer 2023',
#               'genesis g70 2019',
#               'genesis g70 2020',
#               'genesis g80 2020',
#               'genesis g80 2023',
#               'genesis g90 2021',
#               'genesis g90 2022',
#               'hyundai avante 2021',
#               'hyundai avante 2022']
# dic={
#     'chevrolet spark 2020':0,
#               'chevrolet spark 2022':1,
#               'chevrolet trailblazer 2020':2,
#               'chevrolet trailblazer 2023':3,
#               'genesis g70 2019':4,
#               'genesis g70 2020':5,
#               'genesis g80 2020':6,
#               'genesis g80 2023':7,
#               'genesis g90 2021':8,
#               'genesis g90 2022':9,
#               'hyundai avante 2021':10,
#               'hyundai avante 2022':11
# }

image_datas = glob('/gdrive/My Drive/datasets/*/*.*')
X=[]
Y=[]
for imagename in image_datas : 
  image = Image.open(imagename)

  image = image.resize((224, 224))
  image = np.array(image)
  if image.shape == (224, 224, 3) :
    X.append(image)
    label = imagename.split('/')[4]
    label = dic[label]
    Y.append(label)
  else :
    print(imagename, image.shape)

# print(X.shape)

X = np.array(X)
Y = np.array(Y)

train_images, test_images, train_labels, test_labels = train_test_split(X, Y, test_size=0.2, shuffle = True, random_state = 44)

train_labels = train_labels[..., tf.newaxis]
test_labels = test_labels[..., tf.newaxis]

train_images.shape, train_labels.shape, test_images.shape, test_labels.shape

N_TRAIN = train_images.shape[0]
N_TEST = test_images.shape[0]
N_CLASS = len(class_name)

print(N_TRAIN, N_TEST, N_CLASS)

# 클래스별 이미지 개수 확인 (train 이미지)
unique, counts = np.unique(np.reshape(train_labels, (N_TRAIN,)), axis=-1, return_counts=True)
dict(zip(unique, counts))

# 클래스별 이미지 개수 확인 (test 이미지)
unique, counts = np.unique(np.reshape(test_labels, (N_TEST,)), axis=-1, return_counts=True)
dict(zip(unique, counts))

plt.figure(figsize=(N_CLASS,50))
for i in range(N_CLASS) : 
  img_idx = np.random.randint(0,N_TRAIN)
  plt.subplot(11,6,i+1)
  plt.xticks([])
  plt.yticks([])
  plt.grid(False)
  plt.imshow(train_images[img_idx])
  plt.xlabel(class_name[train_labels[img_idx][0]])

#기존 0~255 값을 가지던 픽셀값을 0~1사이 범위로 조정
train_images = train_images.astype(np.float32) / 255.
test_images = test_images.astype(np.float32) / 255.

train_labels = keras.utils.to_categorical(train_labels)
test_labels = keras.utils.to_categorical(test_labels)

print(train_images.shape, train_labels.shape)
print(test_images.shape, test_labels.shape)

#파라미터
learning_rate = 0.02
N_EPOCHS = 20
N_BATCH = 30

#train 이미지, test 이미지 나눴던걸 이용해서 데이터셋 구성
train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(buffer_size=N_TRAIN).batch(N_BATCH).repeat()
test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(N_BATCH)

# train_dataset
# test_dataset

#모델구성
from keras.applications import ResNet50

def create_model():
  model = keras.Sequential()
  #resnet50 모델을 이용하여 224X224의 이미지 데이터 분류
  model.add(ResNet50(include_top=True, weights=None, input_shape=(224, 224, 3), classes=N_CLASS))
  return model

model = create_model()
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()

steps_per_epoch = N_TRAIN//N_BATCH
validation_steps = N_TEST//N_BATCH
print(steps_per_epoch, validation_steps)

#모델 학습
history = model.fit(train_dataset, 
                              epochs=N_EPOCHS, 
                              steps_per_epoch=steps_per_epoch,
                              validation_data=test_dataset, 
                              validation_steps=validation_steps)

model.evaluate(test_dataset)

plt.plot(history.history['loss'], 'b-', label='loss')
plt.plot(history.history['val_loss'], 'r--', label='val_loss')
plt.xlabel('Epoch')
plt.legend()
plt.show()

plt.plot(history.history['accuracy'], 'b-', label='accuracy')
plt.plot(history.history['val_accuracy'], 'r--', label='val_accuracy')
plt.xlabel('Epoch')
plt.legend()
plt.show()

#*결과 확인
def plot_image(i, predictions_array, true_label, img) :
  predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]
  plt.grid(False)
  plt.xticks ([])
  plt.yticks ([])

  plt.imshow (img)

  predicted_label = np.argmax(predictions_array)
  if predicted_label == true_label :
    color ='blue'
  else :
    color = 'red'

  plt.xlabel("{} {:2.0f}% ({})".format(class_name[predicted_label],
  100*np.max (predictions_array),
  class_name [true_label]),
  color=color)

def plot_value_array(i, predictions_array, true_label) :
  predictions_array, true_label = predictions_array[i], true_label[i]
  plt.grid(False) 
  #plt.xticks ([1])
  plt.xticks (range(N_CLASS) ,class_name, rotation=90)
  plt.yticks ([])
  thisplot = plt.bar(range(N_CLASS), predictions_array, color="#777777")
  plt.ylim([0, 1])
  predicted_label = np.argmax (predictions_array)

  thisplot[predicted_label].set_color('red')
  thisplot[true_label].set_color('blue')

rnd_idx = np.random.randint(1, N_TEST//N_BATCH)
img_cnt = 0
for images, labels in test_dataset:
  img_cnt += 1
  if img_cnt != rnd_idx:
    continue
  predictions = model(images, training=False)
  num_rows = N_ROW
  num_cols = N_COL
  num_images = num_rows*num_cols
  labels = tf.argmax(labels, axis=-1)
  plt.figure(figsize=(3*2*num_cols, 4*num_rows))
  plt.subplots_adjust(hspace=1.0)

  for i in range(num_images) :
    plt.subplot(num_rows, 2*num_cols, 2*i+1)
    plot_image(i, predictions.numpy(), labels.numpy() , images.numpy())
    plt.subplot(num_rows, 2*num_cols, 2*i+2)
    plot_value_array(i, predictions.numpy(), labels.numpy())
  break